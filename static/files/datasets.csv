Paper Title,Dataset Name,Benchmark,Application Domain,Reward,Human Demonstrations,Simplified / Real-World,Simulated / Crawled,Multi-User-Instruction,Observatio Space,Action Space,Number of Samples/Tasks,Extras
"Shi et al. ""World of Bits: An Open-Domain Platform for Web-Based Agents""",MiniWoB,Yes,Web,Yes,Yes,"Simplified, Real-World",Simulated,No,Bi-Modal,Mouse/ Touch/Keyboard,MiniWoB: 100 tasks; FormWoB: four web tasks based in real flight booking websites (but with man-in-the-middle proxy for approximation of the live website); QAWoB: 11650 queries (from 521 templates) ,
"Liu et al. ""Reinforcement Learning on Web Interfaces Using Workflow-Guided Exploration""",MiniWoB++,No,Web,Yes,Yes,Simplified,Simulated,No,Textual,Direct UI Access,library that contains a collection of over 100 web interaction environments,use demonstrations to constrain exploration; pruning away bad exploration directions --> can accelerate the agentâ€™s ability to discover sparse rewards
"Xu et al. ""Grounding Open-Domain Instructions to Automate Web Support Tasks""",RUSS,No,Web,No,No,Real-World,"Crawled, Simulated",Yes,Textual,Direct UI Access,"80 different customer service problems from help websites, with a total of 741 step-by-step instructions (RUSS evaluation) &  1.5M natural language instructions (RUSS synthetic)",
"Gur et al. ""Environment Generation for Zero-Shot Compositional Reinforcement Learning""",gMiniWoB,unknown,Web,Yes,No,Simplified,Simulated,No,Bi-Modal,Direct UI Access,,
"Yao et al. ""WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents""",WebShop,No,Web,Yes,Yes,Real-World,"Crawled, Simulated",No,Textual,"Direct UI Access, Task tailored","1181436 products from amazon.com across 5 categories (fashion, makeup, electronics, furniture, and food); 12087 linguistically diverse instructions collected from AMTs",
"Deng et al. ""Mind2Web: Towards a Generalist Agent for the Web""",Mind2Web,No,Web,No,No,Real-World,Crawled,No,Textual,Mouse/ Touch/Keyboard,2350 open-ended tasks collected from 137 websites spanning 31 domains,"provides three elements for generalist web-agents: divers domains, websites, tasks; use of real-world websites; broad spectrum of user interactions"
"Koroglu et al. ""QBE: QLearning-Based Exploration of Android Applications""",QBE-F-Droid,unknown,Android,No,Yes,Real-World,Crawled,No,Textual,Direct UI Access,100 AUT,
"Rawles et al. ""Android in the Wild: A Large-Scale Dataset for Android Device Control""",Android in the Wild,No,"Android, Web",No,Yes,Simplified,Crawled,No,Image ( UI Screenshot),Mouse/ Touch/Keyboard,"715,142 episodes, spanning 30,378 unique prompts","consists of four multi-step datasets, GOOGLEAPPS, INSTALL, WEBSHOPPING, and GENERAL, along with a single-step dataset SINGLE"
"Zhou et al. ""WebArena: A Realistic Web Environment for building autonomous agents""",WebArena,No,Web,Yes,No,Simplified,Crawled,No,Bi-Modal,Mouse/ Touch/Keyboard,812 tasks,
"Li et al. ""Mapping Natural Language Instructions to Mobile UI Action Sequences""",PixelHelp,No,Android,No,No,Simplified,Crawled,No,Bi-Modal,"Direct UI Access, Mouse/ Touch/Keyboard","PixelHelp: 187 multi-step instructions of 4 task categories: 88 general tasks, such as configuring accounts, 38 Gmail tasks, 31 Chrome tasks, and 30 Photos related tasks; AndroidHowTo: 32,436 data points from 9,893 unique How-To instructions and split into training (8K), validation (1K) and test (900); RiscoSCA: 72K Android UI screens mined from 9.7K Android apps",PIXELHELP: instructions for performing common tasks on Google Pixel phonesANDROIDHOWTO: support learning the action phrase extraction model; RICOSCA: for training the grounding model
"Toyama et al. ""AndroidEnv: A Reinforcement Learning Platform for Android""",AndroidEnv,No,Android,Yes,No,Real-World,Simulated,No,Textual,Direct UI Access,initial set of ready-to-use tasks: over 100 tasks across roughly 30 different apps,
"Burns et al. ""A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility""",MoTIF,No,Android,No,Yes,Real-World,Crawled,No,Bi-Modal,Mouse/ Touch/Keyboard,over 6100 natural language tasks across 125 Android apps,
"Xie et al. ""OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments""",OSWorld,Yes,Desktop,Yes,No,Real-World,Crawled,No,Bi-Modal,Mouse/ Touch/Keyboard,369 real computing tasks defined and executed on Ubuntu; 43 tasks for Windows,
"Shvo et al. ""AppBuddy: Learning to Accomplish Tasks in Mobile Apps via Reinforcement Learning""",AppBuddy,Yes,Android,Yes,No,Simplified,Simulated,No,Textual,Direct UI Access,4 mobile apps with 3 task,
"Sun et al. ""META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI""",Meta-GUI,No,Android,No,Yes,Real-World,Crawled,Yes,Bi-Modal,Direct UI Access,1125 tasks,
"Liu et al. ""AgentBench: Evaluating LLMs as Agents""",AgentBench,Yes,"Desktop, Web",No,No,Real-World,Simulated,No,Multi-Modal,Task tailored,8 distinct environments; 27 LLMs are examined,systematic benchmark to evaluate LLM-as-Agent on a wide array of real-world challenges and 8 distinct environments
"Chen et al. ""WebVLN: Vision-and-Language Navigation on Websites""",WebVLN,No,Web,No,No,Real-World,Crawled,No,Bi-Modal,Direct UI Access,8990 records/paths with 14825 QA pairs derived from three different shopping websites,
"Song et al. ""RestGPT: Connecting Large Language Models with Real-World RESTful APIs""",RestBench,Yes,API-Calls,No,Yes,Simplified,Crawled,No,Other,API-Call,157 tasks,
"Koh et el. ""VisualWebArena: Evaluating Multimodal Agents on Realistic Visually Grounded Web Tasks""",VisualWebArena,Yes,Web,Yes,Yes,Real-World,Crawled,No,Bi-Modal,Direct UI Access,910 realistic tasks over three diverse web environments,"Classifieds environment is a new contribution with real world data, while the Shopping and Reddit environments are inherited from WebArena"
"Deng et al. ""On the Multi-turn Instruction Following for Conversational Web Agents""",MT-Mind2Web,No,Web,No,No,Real-World,Simulated,Yes,Textual,Direct UI Access,"720 web navigation conversation sessions, which contain 3,525 corresponding instruction",
"Kapoor et al. ""OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web""",OmniACT,Yes,"Desktop, Web",No,Yes,Simplified,Crawled,No,Bi-Modal,Mouse/ Touch/Keyboard,9802 tasks across more than 200 desktop and web screens,performance measurement of autonomous agents on web and desktop applications
"Wen et al. ""Empowering LLM to use Smartphone for Intelligent Task Automation""",DroidTask,Yes,Android,No,Yes,Real-World,Crawled,No,Image ( UI Screenshot),Direct UI Access,158 common tasks,
"Gao et al. ""ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation""",AssistGUI,Yes,Desktop,No,No,Real-World,Crawled,No,Bi-Modal,Mouse/ Touch/Keyboard,100 tasks from nine widely-used software applications,
"Niu et al. ""ScreenAgent: A Vision Language Model-driven Computer Control Agent""",ScreenAgent,No,Desktop,No,Yes,Real-World,Simulated,No,Image ( UI Screenshot),Mouse/ Touch/Keyboard,"39 sub-task categories across 6 themes; 273 complete task sessions, with 203 sessions (3005 screenshots) for training and 70 sessions (898 screenshots) for testing",
"Drouin et al. ""WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?""",WorkArena,Yes,Web,No,Yes,Real-World,Crawled,No,Bi-Modal,"Mouse/ Touch/Keyboard, Direct UI Access",19912 tasks of 33 categories ,
"Lai et al. ""AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent""",AutoWebBench,Yes,Web,No,Yes,Real-World,Crawled,No,Bi-Modal,Direct UI Access,?,
"Zhang et al.  ""Android in the Zoo: Chain-of-Action-Thought for GUI Agents""",Android in the zoo,No,Android,No,Yes,Simplified,Crawled,No,Image ( UI Screenshot),Direct UI Access,2504 tasks across 70 apps averaging 7.5 actions,
"Chen et al. ""GUICourse: From General Vision Language Models to Versatile GUI Agents""",GUIAct,No,"Android, Web",No,No,Real-World,Crawled,No,Image ( UI Screenshot),Direct UI Access,GUIEnv:10M website pageannotation pairs; GUIAct: 67k single-step and 15000 multi-step action instructions; GUIChat: 44000 single-turn QA pairs and 6000 multi-turn dialogues ,
"Guo et al. ""PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task Completion""",PPTC,Yes,Office,No,Yes,Simplified,Crawled,Yes,Textual,API-Call,279 multi-turn sessions (each includes 2 to 17 turns),
"Venkatesh et al. ""UGIF: UI Grounded Instruction Following""",UGIF,No,Android,No,Yes,Simplified,Crawled,No,Bi-Modal,Direct UI Access,4184 tasks across 8 languages,
"Zheng et al. ""AgentStudio: A Toolkit for Building General Virtual Agents""",AgentStudio,Yes,"Web, Desktop",Yes,Yes,Real-World,Crawled,No,Multi-Modal,"Mouse/ Touch/Keyboard, API-Call",GroundUI (18K single-step instruction-screenshot pairs); ,"provides the most generic observation and action spaces, which significantly expands the task space, allowing for developing and evaluating agents in real-world settings"
"Zhang et al. ""Mobile-Env: An Evaluation Platform and Benchmark for LLM-GUI Interaction""",Mobile-Env,No,Android,No,Yes,Real-World,Crawled,Yes,Bi-Modal,Mouse/ Touch/Keyboard,74 GUI interaction tasks,
"Chen et al. ""GUI-WORLD: A Dataset for GUI-oriented Multimodal LLM-based Agents""",GUI-World,No,"Desktop, Android, IOS, Web",No,Yes,Real-World,Crawled,Yes,Image ( UI Screenshot),Mouse/ Touch/Keyboard,"over 12,000 videos",
"Chai et al. ""AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents""",AMEX,unknown,Android,,,,,,,,,